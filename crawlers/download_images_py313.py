"""
å®¶å…·ææ–™æ£€æµ‹å’Œäººä½“å·¥å­¦æ£€æµ‹ - æµ‹è¯•å›¾ç‰‡æ‰¹é‡ä¸‹è½½è„šæœ¬ (Python 3.13å…¼å®¹ç‰ˆ)

åŠŸèƒ½ï¼š
1. æ‰¹é‡ä¸‹è½½å®¶å…·ç…§ç‰‡ï¼ˆå®æœ¨ã€æ¿æã€çš®è´¨æ²™å‘ã€å¸ƒè‰ºæ²™å‘ç­‰ï¼‰
2. æ‰¹é‡ä¸‹è½½åå§¿ç…§ç‰‡ï¼ˆæ ‡å‡†åå§¿ã€é©¼èƒŒã€æ¤…å­é«˜åº¦é—®é¢˜ç­‰ï¼‰
3. è‡ªåŠ¨åˆ†ç±»ä¿å­˜åˆ°ä¸åŒæ–‡ä»¶å¤¹
4. ä½¿ç”¨Unsplashå’ŒPexels APIï¼ˆå…è´¹ï¼‰

ä¾èµ–å®‰è£…ï¼š
pip install requests pillow tqdm

ä½¿ç”¨æ–¹æ³•ï¼š
python download_images_py313.py
"""

import os
import sys
import time
import hashlib
from pathlib import Path
from urllib.parse import urlencode

try:
    import requests
    from PIL import Image
    from io import BytesIO
    from tqdm import tqdm
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–åº“ï¼è¯·å…ˆå®‰è£…ï¼š")
    print("pip install requests pillow tqdm")
    sys.exit(1)

# é…ç½®å‚æ•°
CONFIG = {
    "output_dir": "test_images_py313",  # è¾“å‡ºç›®å½•
    "limit_per_keyword": 5,  # æ¯ä¸ªå…³é”®è¯ä¸‹è½½æ•°é‡
    "min_width": 1280,  # æœ€å°å®½åº¦
    "min_height": 720,  # æœ€å°é«˜åº¦
    "timeout": 30,  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
}

# Unsplash APIé…ç½®ï¼ˆå…è´¹ï¼Œæ— éœ€æ³¨å†Œä¹Ÿå¯ä½¿ç”¨æœç´¢ï¼‰
UNSPLASH_API = "https://unsplash.com/napi/search/photos"

# Pexels APIé…ç½®ï¼ˆéœ€è¦æ³¨å†Œè·å–API keyï¼Œè¿™é‡Œä½¿ç”¨å…¬å¼€æœç´¢ï¼‰
PEXELS_SEARCH = "https://www.pexels.com/search"

# å›¾ç‰‡åˆ†ç±»å’Œæœç´¢å…³é”®è¯
IMAGE_CATEGORIES = {
    "å®¶å…·ç…§ç‰‡": {
        "å®æœ¨æ¡Œæ¤…": [
            "solid wood dining table",
            "wooden desk natural grain",
            "oak furniture texture",
        ],
        "æ¿æå®¶å…·": [
            "particle board furniture",
            "laminated cabinet",
            "MDF furniture",
        ],
        "çš®è´¨æ²™å‘_çœŸçš®": [
            "genuine leather sofa",
            "full grain leather couch",
            "top grain leather furniture",
        ],
        "çš®è´¨æ²™å‘_PUçš®": [
            "PU leather sofa",
            "faux leather couch",
            "synthetic leather furniture",
        ],
        "çš®è´¨æ²™å‘_ç§‘æŠ€å¸ƒ": [
            "tech fabric sofa",
            "microfiber couch",
            "performance fabric furniture",
        ],
        "å¸ƒè‰ºæ²™å‘_æ£‰éº»": [
            "linen sofa",
            "cotton linen couch",
            "natural fabric furniture",
        ],
        "å¸ƒè‰ºæ²™å‘_ç»’å¸ƒ": [
            "velvet sofa",
            "plush couch",
            "velour furniture",
        ],
        "åŠ£è´¨å®¶å…·": [
            "poor quality furniture defects",
            "furniture damage peeling",
            "bad furniture edge",
        ],
        "é«˜è´¨é‡å®¶å…·": [
            "high quality furniture craftsmanship",
            "luxury furniture detail",
            "premium furniture finish",
        ],
    },
    "åå§¿ç…§ç‰‡": {
        "æ ‡å‡†åå§¿": [
            "correct sitting posture side view",
            "proper desk posture ergonomic",
            "good sitting position office",
        ],
        "é©¼èƒŒåå§¿": [
            "slouching posture bad",
            "hunched back sitting",
            "poor posture desk",
        ],
        "æ¤…å­è¿‡é«˜": [
            "chair too high feet dangling",
            "high chair posture problem",
            "elevated seat posture",
        ],
        "æ¤…å­è¿‡ä½": [
            "chair too low knees bent",
            "low seat posture issue",
            "sitting low chair",
        ],
        "ä¸åŒèº«é«˜": [
            "different heights sitting",
            "tall short people chairs",
            "various body types seating",
        ],
    },
}


class ImageDownloader:
    def __init__(self, output_dir, timeout=30):
        self.output_dir = Path(output_dir)
        self.timeout = timeout
        self.downloaded_hashes = set()
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def get_image_hash(self, image_data):
        """è®¡ç®—å›¾ç‰‡çš„MD5å“ˆå¸Œå€¼ç”¨äºå»é‡"""
        return hashlib.md5(image_data).hexdigest()

    def download_from_unsplash(self, query, limit=5):
        """ä»Unsplashä¸‹è½½å›¾ç‰‡"""
        images = []
        try:
            params = {
                'query': query,
                'per_page': limit * 2,  # å¤šä¸‹è½½ä¸€äº›ä»¥é˜²è¿‡æ»¤åä¸å¤Ÿ
                'orientation': 'landscape'
            }

            response = self.session.get(
                UNSPLASH_API,
                params=params,
                timeout=self.timeout
            )

            if response.status_code == 200:
                data = response.json()
                results = data.get('results', [])

                for item in results[:limit * 2]:
                    try:
                        # è·å–å¸¸è§„å°ºå¯¸çš„å›¾ç‰‡URL
                        img_url = item.get('urls', {}).get('regular')
                        if not img_url:
                            continue

                        # ä¸‹è½½å›¾ç‰‡
                        img_response = self.session.get(img_url, timeout=self.timeout)
                        if img_response.status_code == 200:
                            img_data = img_response.content

                            # æ£€æŸ¥æ˜¯å¦é‡å¤
                            img_hash = self.get_image_hash(img_data)
                            if img_hash in self.downloaded_hashes:
                                continue

                            # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸
                            try:
                                img = Image.open(BytesIO(img_data))
                                if img.width >= CONFIG['min_width'] and img.height >= CONFIG['min_height']:
                                    images.append(img_data)
                                    self.downloaded_hashes.add(img_hash)

                                    if len(images) >= limit:
                                        break
                            except Exception:
                                continue

                        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«

                    except Exception as e:
                        continue

        except Exception as e:
            print(f"  âš ï¸ Unsplashæœç´¢å¤±è´¥: {e}")

        return images

    def download_images(self, category, subcategory, keywords, limit):
        """ä¸‹è½½æŒ‡å®šç±»åˆ«çš„å›¾ç‰‡"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = self.output_dir / category / subcategory
        output_path.mkdir(parents=True, exist_ok=True)

        print(f"\nğŸ“¥ ä¸‹è½½ {category}/{subcategory}")

        all_images = []

        # å¯¹æ¯ä¸ªå…³é”®è¯è¿›è¡Œæœç´¢
        for keyword in keywords:
            if len(all_images) >= limit:
                break

            print(f"  ğŸ” æœç´¢: {keyword}")

            # ä»Unsplashä¸‹è½½
            images = self.download_from_unsplash(keyword, limit=limit - len(all_images))
            all_images.extend(images)

            if len(all_images) >= limit:
                break

        # ä¿å­˜å›¾ç‰‡
        saved_count = 0
        for idx, img_data in enumerate(all_images[:limit], 1):
            try:
                # ç”Ÿæˆæ–‡ä»¶å
                filename = f"{subcategory.replace('/', '_')}_{idx:03d}.jpg"
                filepath = output_path / filename

                # ä¿å­˜å›¾ç‰‡
                with open(filepath, 'wb') as f:
                    f.write(img_data)

                saved_count += 1

            except Exception as e:
                print(f"  âš ï¸ ä¿å­˜å¤±è´¥: {e}")

        print(f"  âœ… æˆåŠŸä¸‹è½½ {saved_count} å¼ å›¾ç‰‡")
        return saved_count


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("å®¶å…·ææ–™æ£€æµ‹å’Œäººä½“å·¥å­¦æ£€æµ‹ - æµ‹è¯•å›¾ç‰‡ä¸‹è½½å·¥å…· (Python 3.13)")
    print("=" * 60)

    # é€‰æ‹©ä¸‹è½½ç±»åˆ«
    print("\nè¯·é€‰æ‹©ä¸‹è½½ç±»åˆ«ï¼š")
    print("1. ä»…ä¸‹è½½å®¶å…·ç…§ç‰‡")
    print("2. ä»…ä¸‹è½½åå§¿ç…§ç‰‡")
    print("3. ä¸‹è½½å…¨éƒ¨ï¼ˆé»˜è®¤ï¼‰")

    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3ï¼Œç›´æ¥å›è½¦é€‰æ‹©3): ").strip()

    categories_to_download = []
    if choice == "1":
        categories_to_download = ["å®¶å…·ç…§ç‰‡"]
    elif choice == "2":
        categories_to_download = ["åå§¿ç…§ç‰‡"]
    else:
        categories_to_download = ["å®¶å…·ç…§ç‰‡", "åå§¿ç…§ç‰‡"]

    # åˆ›å»ºä¸‹è½½å™¨
    downloader = ImageDownloader(
        output_dir=CONFIG["output_dir"],
        timeout=CONFIG["timeout"]
    )

    # ç»Ÿè®¡ä¿¡æ¯
    total_downloaded = 0
    total_categories = 0

    # å¼€å§‹ä¸‹è½½
    print(f"\nå¼€å§‹ä¸‹è½½åˆ°ç›®å½•: {CONFIG['output_dir']}")
    print(f"æ¯ä¸ªç±»åˆ«ä¸‹è½½: {CONFIG['limit_per_keyword']} å¼ ")
    print(f"æœ€å°åˆ†è¾¨ç‡: {CONFIG['min_width']}x{CONFIG['min_height']}")

    for category in categories_to_download:
        if category not in IMAGE_CATEGORIES:
            continue

        print(f"\n{'='*60}")
        print(f"ğŸ“‚ {category}")
        print(f"{'='*60}")

        for subcategory, keywords in IMAGE_CATEGORIES[category].items():
            count = downloader.download_images(
                category=category,
                subcategory=subcategory,
                keywords=keywords,
                limit=CONFIG["limit_per_keyword"]
            )
            total_downloaded += count
            total_categories += 1

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"âœ… ä¸‹è½½å®Œæˆï¼")
    print(f"{'='*60}")
    print(f"æ€»ç±»åˆ«æ•°: {total_categories}")
    print(f"æ€»ä¸‹è½½æ•°: {total_downloaded} å¼ ")
    print(f"ä¿å­˜ä½ç½®: {CONFIG['output_dir']}")
    print(f"\nğŸ’¡ æç¤º: ä¸‹è½½çš„å›¾ç‰‡å·²æŒ‰ç±»åˆ«æ•´ç†ï¼Œå¯ä»¥ç›´æ¥ç”¨äºæµ‹è¯•")


if __name__ == "__main__":
    main()
